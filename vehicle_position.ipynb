{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7b026eeb-6b79-4f83-9e7f-bde60c3e3013",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import from_json, col, expr, to_timestamp, unix_timestamp, to_date, concat, lit, format_string, when, from_utc_timestamp\n",
    "from pyspark.sql.types import *\n",
    "import math\n",
    "from pyspark.sql.functions import udf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "55736107-8b22-47bc-ae1e-e52bc8c85ff9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "25/08/21 09:55:34 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "25/08/21 09:55:35 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n",
      "25/08/21 09:55:35 WARN Utils: Service 'SparkUI' could not bind on port 4041. Attempting port 4042.\n",
      "25/08/21 09:55:35 WARN Utils: Service 'SparkUI' could not bind on port 4042. Attempting port 4043.\n"
     ]
    }
   ],
   "source": [
    "# Initialize Spark Session\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"GTFSRealtimeVPProcessing\") \\\n",
    "    .master(\"local[*]\") \\\n",
    "    .config(\"spark.sql.session.timeZone\", \"America/New_York\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "925cec0a-31c5-4a3c-9e89-e118c065a89e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Schema of vehicle position data\n",
    "# vehicle_schema = StructType([\n",
    "#     StructField(\"header\", StructType([\n",
    "#         StructField(\"gtfsRealtimeVersion\", StringType()),\n",
    "#         StructField(\"timestamp\", StringType())\n",
    "#     ])),\n",
    "#     StructField(\"entity\", ArrayType(StructType([\n",
    "#         StructField(\"id\", StringType()),\n",
    "#         StructField(\"vehicle\", StructType([\n",
    "#             StructField(\"trip\", StructType([\n",
    "#                 StructField(\"tripId\", StringType()),\n",
    "#                 StructField(\"routeId\", StringType()),\n",
    "#                 StructField(\"startDate\", StringType())\n",
    "#             ])),\n",
    "#             StructField(\"position\", StructType([\n",
    "#                 StructField(\"latitude\", DoubleType()),\n",
    "#                 StructField(\"longitude\", DoubleType())\n",
    "#             ])),\n",
    "#             StructField(\"timestamp\", StringType())\n",
    "#         ]))\n",
    "#     ])))\n",
    "# ])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "vehicle_schema = StructType([\n",
    "    StructField(\"header\", StructType([\n",
    "        StructField(\"gtfsRealtimeVersion\", StringType())\n",
    "    ])),\n",
    "    StructField(\"entity\", ArrayType(StructType([\n",
    "        StructField(\"id\", StringType()),\n",
    "        StructField(\"vehicle\", StructType([\n",
    "            StructField(\"trip\", StructType([\n",
    "                StructField(\"tripId\", StringType()),\n",
    "                StructField(\"routeId\", StringType()),\n",
    "                StructField(\"startDate\", StringType())\n",
    "            ])),\n",
    "            StructField(\"position\", StructType([\n",
    "                StructField(\"latitude\", DoubleType()),\n",
    "                StructField(\"longitude\", DoubleType())\n",
    "            ])),\n",
    "            StructField(\"timestamp\", StringType())\n",
    "        ]))\n",
    "    ])))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0c4b5e0c-9e32-4058-bde9-c55d748b51d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ClickHouse connection details\n",
    "clickhouse_url = \"jdbc:clickhouse://clickhouse:8123\"\n",
    "clickhouse_properties = {\n",
    "    \"user\": \"default\",\n",
    "    \"password\": \"123\",\n",
    "    \"driver\": \"com.clickhouse.jdbc.ClickHouseDriver\",\n",
    "    \"isolationLevel\": \"NONE\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fd448cb0-8ecb-4497-8669-bf3702a4c4e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read and process vehicle positions from Kafka\n",
    "vp_raw_df = spark.readStream \\\n",
    "    .format(\"kafka\") \\\n",
    "    .option(\"kafka.bootstrap.servers\", \"broker:29092\") \\\n",
    "    .option(\"subscribe\", \"gtfs-vehicle-positions\") \\\n",
    "    .option(\"startingOffsets\", \"earliest\") \\\n",
    "    .load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ad39da1e-4852-4e37-8dc6-e1613fc2772c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# vp_kafka_df = vp_raw_df.selectExpr(\"CAST(value AS STRING) AS json_str\",\"topic\")\n",
    "# vp_df = vp_kafka_df.select(from_json(col(\"json_str\"), vehicle_schema).alias(\"data\")) \\\n",
    "#     .select(\"data.*\") \\\n",
    "#     .withColumn(\"header_timestamp\", to_timestamp(col(\"header.timestamp\").cast(\"long\"))) \\\n",
    "#     .withColumn(\"vehicle_timestamp\", to_timestamp(col(\"entity.vehicle.timestamp\").cast(\"long\"))) \\\n",
    "#     .withWatermark(\"header_timestamp\", \"2 minutes\")\n",
    "\n",
    "\n",
    "\n",
    "vp_kafka_df = vp_raw_df.selectExpr(\"CAST(value AS STRING) AS json_str\")\n",
    "vp_df = vp_kafka_df.select(from_json(col(\"json_str\"), vehicle_schema).alias(\"data\")) \\\n",
    "    .select(\n",
    "        col(\"data.header.gtfsRealtimeVersion\").alias(\"gtfs_version\"),\n",
    "        expr(\"explode(data.entity) as entity\")\n",
    "    ) \\\n",
    "    .withColumn(\n",
    "        \"vehicle_timestamp\",\n",
    "        when(\n",
    "            col(\"entity.vehicle.timestamp\").cast(\"long\").isNotNull(),\n",
    "            to_timestamp(col(\"entity.vehicle.timestamp\").cast(\"long\"))\n",
    "        ).otherwise(lit(None))\n",
    "    ) \\\n",
    "    .withWatermark(\"vehicle_timestamp\", \"2 minutes\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8900ae61-c42f-46b2-a94a-235b80931416",
   "metadata": {},
   "outputs": [],
   "source": [
    "# vp_exploded_df = vp_df.select(\n",
    "#     col(\"header.gtfsRealtimeVersion\").alias(\"gtfs_version\"),\n",
    "#     col(\"header_timestamp\"),\n",
    "#     expr(\"explode(entity) as entity\"),\n",
    "#     col(\"kafka_timestamp\")\n",
    "# ).select(\n",
    "#     col(\"gtfs_version\"),\n",
    "#     col(\"header_timestamp\"),\n",
    "#     col(\"entity.id\").alias(\"entity_id\"),\n",
    "#     col(\"entity.vehicle.trip.tripId\").alias(\"vp_trip_id\"),\n",
    "#     col(\"entity.vehicle.trip.routeId\").alias(\"route_id\"),\n",
    "#     col(\"entity.vehicle.trip.startDate\").alias(\"vp_start_date\"),\n",
    "#     col(\"entity.vehicle.position.latitude\").alias(\"latitude\"),\n",
    "#     col(\"entity.vehicle.position.longitude\").alias(\"longitude\"),\n",
    "#     col(\"entity.vehicle.timestamp\").alias(\"vehicle_timestamp\"),\n",
    "#     col(\"kafka_timestamp\")\n",
    "# ).filter(col(\"vp_trip_id\").isNotNull())\n",
    "\n",
    "\n",
    "\n",
    "vp_exploded_df = vp_df.select(\n",
    "    col(\"gtfs_version\"),\n",
    "    col(\"entity.id\").alias(\"entity_id\"),\n",
    "    col(\"entity.vehicle.trip.tripId\").alias(\"vp_trip_id\"),\n",
    "    col(\"entity.vehicle.trip.routeId\").alias(\"route_id\"),\n",
    "    col(\"entity.vehicle.trip.startDate\").alias(\"vp_start_date\"),\n",
    "    col(\"entity.vehicle.position.latitude\").alias(\"latitude\"),\n",
    "    col(\"entity.vehicle.position.longitude\").alias(\"longitude\"),\n",
    "    col(\"vehicle_timestamp\")\n",
    ").filter(col(\"vp_trip_id\").isNotNull())\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c1ded509-ed58-49da-9c1c-084303571821",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write vehicle positions to ClickHouse\n",
    "def write_vp_to_clickhouse(batch_df, batch_id):\n",
    "    try:\n",
    "        batch_df.write \\\n",
    "            .format(\"jdbc\") \\\n",
    "            .option(\"url\", f\"{clickhouse_url}/gtfs_streaming\") \\\n",
    "            .option(\"dbtable\", \"vehicle_positions2\") \\\n",
    "            .option(\"user\", clickhouse_properties[\"user\"]) \\\n",
    "            .option(\"password\", clickhouse_properties[\"password\"]) \\\n",
    "            .option(\"driver\", clickhouse_properties[\"driver\"]) \\\n",
    "            .mode(\"append\") \\\n",
    "            .save()\n",
    "    except Exception as e:\n",
    "        print(f\"Vehicle Positions write error: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "27b1323d-821d-43ab-a368-7074fddb15cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/08/21 09:55:44 WARN ResolveWriteToStream: spark.sql.adaptive.enabled is not supported in streaming DataFrames/Datasets and will be disabled.\n",
      "25/08/21 09:55:45 WARN AdminClientConfig: These configurations '[key.deserializer, value.deserializer, enable.auto.commit, max.poll.records, auto.offset.reset]' were supplied but are not used yet.\n"
     ]
    }
   ],
   "source": [
    "vp_query = vp_exploded_df.writeStream \\\n",
    "    .outputMode(\"append\") \\\n",
    "    .foreachBatch(write_vp_to_clickhouse) \\\n",
    "    .trigger(processingTime=\"30 seconds\") \\\n",
    "    .option(\"checkpointLocation\", \"check_points/vehicle_position_checks\") \\\n",
    "    .start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1ed40db-c50c-4858-ab2a-a6c54555b3f8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12327f57-898f-4f7c-bc2d-5f20da433bc2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92ab1025-8e40-4f0e-845e-03e56f04fbc6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8578fb05-586d-4a78-b0d9-cc9272a669f8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3819f264-36c5-4ad4-8558-3cb486c1293e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec1e7824-6ba1-44a9-9aeb-489670106f6a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12aa4782-870a-47e8-acb7-1b9939afbf30",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7efcc184-fd46-4b52-b883-11a78a17614b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6955aead-17e6-4b39-92f8-6d72f0cdae1e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
