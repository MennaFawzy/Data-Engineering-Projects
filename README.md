# Data-Engineering-Projects

# ğŸšŒ MTA New York Buses - End-to-End Data Engineering Pipeline

<div align="center">


[![Apache Airflow](https://img.shields.io/badge/Airflow-017CEE?style=for-the-badge&logo=apacheairflow&logoColor=white)](https://airflow.apache.org/)
[![Apache Kafka](https://img.shields.io/badge/Kafka-231F20?style=for-the-badge&logo=apachekafka&logoColor=white)](https://kafka.apache.org/)
[![Apache Spark](https://img.shields.io/badge/Spark-E25A1C?style=for-the-badge&logo=apachespark&logoColor=white)](https://spark.apache.org/)
[![Azure](https://img.shields.io/badge/Azure-0078d4?style=for-the-badge&logo=microsoftazure&logoColor=white)](https://azure.microsoft.com/)
[![PostgreSQL](https://img.shields.io/badge/PostgreSQL-336791?style=for-the-badge&logo=postgresql&logoColor=white)](https://postgresql.org/)

[![ClickHouse](https://img.shields.io/badge/ClickHouse-FFCC01?style=for-the-badge&logo=clickhouse&logoColor=black)](https://clickhouse.com/)
[![Power BI](https://img.shields.io/badge/Power%20BI-F2C811?style=for-the-badge&logo=powerbi&logoColor=black)](https://powerbi.microsoft.com/)
[![Metabase](https://img.shields.io/badge/Metabase-509EE3?style=for-the-badge&logo=metabase&logoColor=white)](https://metabase.com/)
[![Docker](https://img.shields.io/badge/Docker-2496ED?style=for-the-badge&logo=docker&logoColor=white)](https://www.docker.com/)


</div>

---
## ğŸ—ï¸ Architecture  ğŸ”¥
![Architecture](./images/pipeline_architecture.png)

---
<div align="center">

 **ğŸ”¥ A comprehensive real-time data engineering solution for NYC MTA bus operations ğŸ”¥**  
 *ğŸš€ Combining batch processing and streaming analytics to optimize transit performance and enhance passenger experience ğŸŒŸ*

</div>

---


## ğŸ“ˆ **Business Impact** ğŸ’¼

### **ğŸ¯ Key Business Benefits** ğŸ”¥

- **âš¡ Improving Operational Efficiency**: Analyze delays ğŸ•’, on-time performance â±ï¸, and alerts ğŸš¨ to identify underperforming routes. Better resource allocation ğŸ’° for maintenance ğŸ”§ and peak hour routing ğŸš¦.

- **ğŸ˜Š Enhancing Passenger Experience**: Real-time vehicle tracking ğŸšŒ and arrival predictions ğŸ”® reduce wait times â³ and increase rider satisfaction ğŸŒŸ.

- **ğŸ’° Cost and Resource Optimization**: Monitor performance trends ğŸ“Š to minimize operational costs ğŸ’¸ and optimize fleet usage ğŸšŒâš¡.

### **ğŸ‘¥ Target Users** ğŸ¯
<div align="center">

ğŸ›ï¸ **City planners and government officials**  
ğŸšŒ **MTA operators and management**  
ğŸ‘¨â€ğŸ‘©â€ğŸ‘§â€ğŸ‘¦ **Public transport users**  
ğŸ¢ **Transport agencies**  

</div>

---

## ğŸ“Š **Data Sources And Web Scraping** ğŸ”¥
<div align="center">
<img src="https://media.giphy.com/media/3oKIPEqDGUULpEU0aQ/giphy.gif" width="350"/>
</div>

### **ğŸ“¦ Batch Data Source** 
<div align="center">

ğŸŒ **Transitland Website**: Batch files containing historical transit data for NYC regions ğŸ—½

</div>

### **ğŸŒŠ Streaming Data Sources** âš¡
<div align="center">

ğŸš€ **GTFS Realtime APIs from Transitland** ğŸ“¡

</div>

| API Endpoint | Update Frequency | Description |
|-------------|------------------|-------------|
| **ğŸšŒ Vehicle Position API** | â° Every 60 seconds | ğŸ“ Actual GPS positions of buses in motion |
| **ğŸš‡ Trip Updates API** | â° Every 60 seconds | â±ï¸ Estimated delays, arrival/departure per stop for running trips |
| **ğŸš¨ Service Alerts API** | ğŸ”´ Real-time | âš ï¸ Service disruptions (road closures, diversions, etc.) |

---


## ğŸ“¦ **Batch Data Processing Pipeline** âš¡
<div align="center">
  <img src="https://media.giphy.com/media/qgQUggAC3Pfv687qPC/giphy.gif" width="400"/>
</div>

### **ğŸ•·ï¸ Data Extraction Process** 
**ğŸ› ï¸ Airflow as the Orchestration Engine** - runs on a fixed schedule every day at ğŸ•› **12:00 AM (NYC time)** â°

#### **ğŸ•¸ï¸ Web Scraping Strategy**
- **âš ï¸ Challenge**: No API available for batch processing - only download button on website ğŸ–±ï¸
- **âœ… Solution**: Automated web scraping to check latest available updates ğŸ¤–
- **ğŸ—ºï¸ Coverage**: Table for each NYC region on the website ğŸŒ†

#### **ğŸ§  Smart Update Detection** ğŸ’¡
The most important aspect is the **ğŸ“… last update timestamp** which determines whether the batch pipeline should run or be skipped:

- **ğŸ“ JSON File Maintenance**: Stores last update date for each region ğŸ—ƒï¸
- **ğŸ” Daily Comparison**: Website's latest update vs. stored date in JSON file âš–ï¸
- **ğŸš« Logic**: If dates match â†’ no new update â†’ skip pipeline (except final task)
- **âœ… Logic**: If dates don't match â†’ proceed with full workflow ğŸš€
---
## ğŸš« skip pipeline
![Airflow 1](./images/Airflow1.png)
---
## âœ… proceed with full workflow 
![Airflow 2](./images/Airflow2.png)
---

### **ğŸ“ Data Processing Workflow** ğŸ”¥
When updates are detected, the workflow proceeds:

1. **ğŸ•·ï¸ Scrape and Download**: Download data as ZIP file ğŸ“¦
2. **ğŸ“‚ Unzip and Convert**: Extract .txt files and convert to .CSV ğŸ“Š
3. **â˜ï¸ Upload to Azure Data Lake**: Upload with proper naming convention (region name, company name, upload date) ğŸ·ï¸
4. **âš¡ Spark Processing**: Airflow triggers Spark Jupyter notebook to extract from Azure Data Lake, apply transformations, and load into PostgreSQL staging database ğŸ˜

### **âš¡ SCD Type 2 Implementation** ğŸ¯
**ğŸ”„ Slowly Changing Dimensions (SCD Type 2)** for historical tracking:

```sql
-- Control columns added to each batch record
ALTER TABLE bus_routes ADD COLUMN start_date TIMESTAMP;
ALTER TABLE bus_routes ADD COLUMN end_date TIMESTAMP;
ALTER TABLE bus_routes ADD COLUMN is_current BOOLEAN;
```

**ğŸ”§ Process**:
- **ğŸŸ¢ start_date**: When record became active âœ…
- **ğŸ”´ end_date**: When record ceased to be current âŒ
- **ğŸ·ï¸ is_current**: Flag indicating latest version ğŸš©

**âš¡ When changes occur**:
- ğŸ’€ Expire old record (set end_date + is_current = False)
- ğŸ†• Insert new record (set start_date, is_current = True)

### **ğŸ¯ Optimized Data Transfer Strategy** ğŸš€
**ğŸ“ˆ Daily Batch Data Transfer to ClickHouse**:
- **ğŸ’¡ Strategy**: Only transfer daily batch data for current day (not entire historical warehouse) ğŸ¯
- **ğŸ”¥ Benefits**:
  - âš¡ **Optimized Spark Load**: Processes only today's data
  - ğŸï¸ **Faster Comparison**: Quick reconciliation with real-time API data
  - ğŸ’° **Reduced Overhead**: Lower storage and processing costs

---

## ğŸŒŠ **Real-time Streaming Pipeline** âš¡

<div align="center">
<img src="https://media.giphy.com/media/3o7qE1YN7aBOFPRw8E/giphy.gif" width="400"/>
</div>

### **ğŸ¯ Streaming Objectives** ğŸ”¥
- ğŸ—ï¸ Build comprehensive real-time data streaming pipeline for transit data
- ğŸ“¡ Continuous ingestion of live transit data with real-time transformation
- ğŸ›ï¸ Processing and analytics-ready storage capabilities

### **ğŸ“¡ Kafka Configuration** âš¡
<div align="center">

ğŸµ **Apache Kafka - The Heart of Our Streaming! ğŸ’“**

</div>

**ğŸ¯ Topic Setup**:
| Topic | Partitions | Retention | Compression |
|-------|-----------|-----------|-------------|
| ğŸš‡ gtfs-trip-updates | 1ï¸âƒ£ | ğŸ“… 7 days | ğŸ—œï¸ snappy |
| ğŸšŒ gtfs-vehicle-positions | 1ï¸âƒ£ | ğŸ“… 7 days | ğŸ—œï¸ snappy |
| ğŸš¨ gtfs-alerts | 1ï¸âƒ£ | ğŸ“… 7 days | ğŸ—œï¸ snappy |

**ğŸ’¡ Partition Reasoning**:
- âš¡ Data processed quickly
- 1ï¸âƒ£ Only 1 message per topic every minute
- ğŸš« No need for parallelism
- ğŸ”„ Replication factor: 1
- ğŸ“Š Max message size: 25MB

### **ğŸ”„ Kafka Producer Responsibilities** ğŸ’ª
- **ğŸ“¥ Data Fetching**: Fetch API data every minute with automatic API key rotation to avoid rate limits ğŸ”‘ğŸ”„
- **ğŸ“Š Metrics Collection**: Push JSON payloads to Kafka topics ğŸ“¤
- **ğŸ‘ï¸ Monitoring**: Log update intervals and payload sizes to ClickHouse ğŸ“ˆ

### **âš¡ Spark Structured Streaming** ğŸ”¥
<div align="center">

ğŸ¯ **Apache Spark - Processing Powerhouse! ğŸ’¥**

</div>

**ğŸ—ï¸ Architecture Benefits**:
- ğŸš€ High-throughput, low-latency pipeline processing
- ğŸ’¾ Built-in checkpointing and fault tolerance
- ğŸ›¡ï¸ Comprehensive error handling

**ğŸ”„ Processing Flow**:
1. **ğŸ“¥ Kafka Consumption**: Offset management and JSON parsing ğŸ“‹
2. **âœ… Schema Validation**: JSON parsing and schema creation ğŸ—‚ï¸
3. **ğŸ”„ Data Transformation**: DataFrame explode and flatten techniques ğŸ“Š
4. **ğŸ’¾ Storage Integration**: Write processed data to ClickHouse âš¡

### **ğŸšŒ Vehicle Positions Processing** ğŸ¯

**âš¡ Advanced Processing Steps**:
1. **ğŸ“ JSON Parsing**: Parse nested JSON structure ğŸ—‚ï¸
2. **ğŸ—ï¸ Schema Creation**: Define data structure ğŸ“
3. **ğŸ”— Static Data Integration**: Read scheduled data from ClickHouse (stops, stop_times) ğŸš
4. **ğŸ¤ Data Joining**: Join vehicle positions with static stops and stop_times ğŸ”—
5. **ğŸ“ Distance Calculation**: Calculate distance using Haversine formula ğŸŒ
6. **ğŸš¦ Status Determination**: 
   - âœ… "arrived" if distance < 100m from stop ğŸšŒğŸš
   - ğŸ›£ï¸ "on_way" otherwise ğŸšŒâ¡ï¸
   - â±ï¸ Calculate delay_seconds


---

## ğŸ›ï¸ Dashboards 
<div align="center">
<img src="https://media.giphy.com/media/l46Cy1rHbQ92uuLXa/giphy.gif" width="350"/>
</div>

---

### **ğŸ“Š Dashboard**
- **Live Vehicle Tracking**: Current positions and status
- **Performance Metrics**: OTP, average delays, alert counts
- **Borough Analysis**: Route performance by geographic region
- **Real-time Monitoring**: Active vehicles and arrival rates
  
### **ğŸ“Š Day-to-Day Dashboard**
![Dashboard](./images/Day-to-Day-Dashboard.png)
---
### **ğŸ“Š Real-time Dashboard**
![Dashboard](./images/Real-time-Dashboard.png)
---

## ğŸš€ **Key Technical Challenges & Solutions** ğŸ’ª

<div align="center">
<img src="https://media.giphy.com/media/zOvBKUUEERdNm/giphy.gif" width="350"/>

*ğŸ’ª Overcoming Technical Mountains! ğŸ”ï¸*
</div>

### **âš¡ Performance Tuning** ğŸ”¥
- **ğŸ› ï¸ Optimized Configurations**: Enhanced Kafka and Spark processing parameters âš™ï¸
- **ğŸ’¾ Resource Management**: Due to RAM limitations on Azure VM, strategic container management needed ğŸ³
- **ğŸ”® Future Enhancement**: Kubernetes recommended for dynamic container orchestration â˜¸ï¸

### **ğŸ”§ Reliability Engineering** ğŸ›¡ï¸
- **ğŸ”„ Error Handling**: Comprehensive retry mechanisms ğŸ”
- **ğŸ‘ï¸ Monitoring**: 24/7 system monitoring on Azure VM ğŸŒ™â˜€ï¸
- **ğŸ’ª Fault Tolerance**: Built-in checkpointing and recovery mechanisms ğŸ¥

### **ğŸ“ˆ System Optimization** ğŸ¯
- **ğŸš€ High-throughput Processing**: Optimized for low-latency streaming âš¡
- **ğŸ“ Scalable Architecture**: Cloud-native design for horizontal scaling ğŸ“ˆ
- **ğŸ’° Cost Efficiency**: Resource-optimized processing strategies ğŸ’¸

---


